{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import joblib \n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppendicitisModel:\n",
    "    def __init__(self):\n",
    "        self._raw_df = None  # Private attribute to store raw DataFrame\n",
    "        self._features = None  # Private attribute for features\n",
    "        self._targets = None  # Private attribute for targets\n",
    "        self._variables = None  # Private attribute for variables\n",
    "        self._continuous_features = None # Private attribute for continuous features\n",
    "        self._categorical_features = None # Private attribute for categorical features \n",
    "        self._integer_features = None # Private attribute for integer features \n",
    "        self._binary_features = None # Private attribute for binary features\n",
    "        self._target = None # Private attribute for binary features \n",
    "        self._continuous_df_features = None # Private attribute for normalized continuous features\n",
    "        self._categorical_df_features = None # Private attribute for encoded categorical features\n",
    "        self._selected_features = None   # Private attribute for engineered features\n",
    "        self._X_preprocessed = None # Private attribute for preprocessed features \n",
    "        self._y_preprocessed = None # Private attribute for preprocessed target \n",
    "        self._preprocessed_data = None # Private attribute for preprocessed data\n",
    "        self._X_train = None # Private attribute for training dataset\n",
    "        self._X_test = None # # Private attribute for test dataset\n",
    "        self._y_train = None # # Private attribute for training dataset\n",
    "        self._y_test = None # Private attribute for test dataset\n",
    "        self._rf_classifier = None # Private attribute random forest objectß\n",
    "        self._y_pred = None # Private attribute for obtained predictions\n",
    "        self._accuracy = None # Private attribute for obtained accuracy\n",
    "        self._confusion_matrix = None # Private attribute for obtained confusion matrix\n",
    "\n",
    "    @property\n",
    "    def features(self):\n",
    "        \"\"\"Return the features of the dataset.\"\"\"\n",
    "        return self._features\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        \"\"\"Return the targets of the dataset.\"\"\"\n",
    "        return self._targets\n",
    "\n",
    "    @property\n",
    "    def raw_df(self):\n",
    "        \"\"\"Return the raw DataFrame containing features and targets.\"\"\"\n",
    "        return self._raw_df\n",
    "\n",
    "    @property\n",
    "    def variables(self):\n",
    "        \"\"\"Return the variables of the dataset.\"\"\"\n",
    "        return self._variables\n",
    "    \n",
    "    @property\n",
    "    def continuous_features(self):\n",
    "        \"\"\"Return the continuous_features of the dataset.\"\"\"\n",
    "        return self._continuous_features\n",
    "    \n",
    "    @property\n",
    "    def categorical_features(self):\n",
    "        \"\"\"Return the categorical_features of the dataset.\"\"\"\n",
    "        return self._categorical_features\n",
    "    \n",
    "    @property\n",
    "    def integer_features(self):\n",
    "        \"\"\"Return the integer_features of the dataset.\"\"\"\n",
    "        return self._integer_features\n",
    "    \n",
    "    @property\n",
    "    def binary_features(self):\n",
    "        \"\"\"Return the binary features of the dataset.\"\"\"\n",
    "        return self._binary_features\n",
    "     \n",
    "    @property\n",
    "    def continuous_df_features(self):\n",
    "        \"\"\"Return the transformed continuous_features of the dataset.\"\"\"\n",
    "        return self._continuous_df_features \n",
    "\n",
    "    @property\n",
    "    def categorical_df_features(self):\n",
    "        \"\"\"Return the transformed categorical_features of the dataset.\"\"\"\n",
    "        return self._categorical_df_features \n",
    "    \n",
    "    @property\n",
    "    def X_preprocessed(self):\n",
    "        \"\"\"Return the preprocessed x features of the dataset.\"\"\"\n",
    "        return self._X_preprocessed\n",
    "\n",
    "    @property\n",
    "    def y_preprocessed(self):\n",
    "        \"\"\"Return the preprocessed y features of the dataset.\"\"\"\n",
    "        return self._y_preprocessed\n",
    "\n",
    "    @property\n",
    "    def preprocessed_data(self):\n",
    "        \"\"\"Return the preprocessed preprocessed dataset.\"\"\"\n",
    "        return self._X_preprocessed_data\n",
    "    \n",
    "    @property\n",
    "    def X_train(self):\n",
    "        \"\"\"Return the preprocessed x_train dataset.\"\"\"\n",
    "        return self._X_train\n",
    "\n",
    "    @property\n",
    "    def X_test(self):\n",
    "        \"\"\"Return the preprocessed x_test dataset.\"\"\"\n",
    "        return self._X_test\n",
    "\n",
    "    @property\n",
    "    def y_train(self):\n",
    "        \"\"\"Return the preprocessed y_train dataset.\"\"\"\n",
    "        return self._y_train\n",
    "\n",
    "    @property\n",
    "    def y_test(self):\n",
    "        \"\"\"Return the preprocessed y_test dataset.\"\"\"\n",
    "        return self._y_test\n",
    "    \n",
    "    @property\n",
    "    def rf_classifier(self):\n",
    "        \"\"\"Return the classifier model.\"\"\"\n",
    "        return self._rf_classifier\n",
    "\n",
    "    @property\n",
    "    def y_pred(self):\n",
    "        \"\"\"Return the predictions from the model.\"\"\"\n",
    "        return self._y_pred\n",
    "    \n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        \"\"\"Return the accuracy of the model.\"\"\"\n",
    "        return self._accuracy\n",
    "\n",
    "    @property\n",
    "    def confusion_matrix(self):\n",
    "        \"\"\"Return the confusion matrix.\"\"\"\n",
    "        return self._confusion_matrix\n",
    "    \n",
    "    @property\n",
    "    def selected_features(self):\n",
    "        \"\"\"Return the selected continuous features.\"\"\"\n",
    "        return self._selected_features\n",
    "\n",
    "\n",
    "    def import_rawdata(self):\n",
    "        \"\"\"Fetch dataset and create dataframes for features, targets, raw_df, and variables.\"\"\"\n",
    "        # Fetch dataset \n",
    "        regensburg_pediatric_appendicitis = fetch_ucirepo(id=938) \n",
    "\n",
    "        # Create dataframes (features, targets, variables, raw_df)\n",
    "        self._features = regensburg_pediatric_appendicitis.data.features \n",
    "        self._targets = regensburg_pediatric_appendicitis.data.targets \n",
    "        self._raw_df = pd.concat([self._features, self._targets], axis=1)\n",
    "        self._variables = regensburg_pediatric_appendicitis.variables  \n",
    "        print(\"Data imported succesfully\")\n",
    "\n",
    "    def save_rawdata(self):\n",
    "        current_directory = os.getcwd()\n",
    "        parent_directory = os.path.dirname(current_directory)\n",
    "        path = os.path.join(parent_directory,'data/raw/uci_df_raw.csv')\n",
    "        self.raw_df.to_csv(path)\n",
    "\n",
    "        print(\"Data stored at:\", path)\n",
    "        return None\n",
    "    \n",
    "    def get_continuous_features(self):\n",
    "        df_featuretype = self.variables[(self.variables['type'] == 'Continuous') & (self.variables['role'] == 'Feature')]\n",
    "        features = df_featuretype['name'].unique()\n",
    "        self._continuous_features = list(features)    \n",
    "        # print(self._continuous_features)   \n",
    "\n",
    "    def get_categorical_features(self):\n",
    "        df_featuretype = self.variables[(self.variables['type'] == 'Categorical') & (self.variables['role'] == 'Feature')]\n",
    "        features = df_featuretype['name'].unique()\n",
    "        self._categorical_features = list(features)\n",
    "        # print(self._categorical_features) \n",
    "\n",
    "    def get_integer_features(self):\n",
    "        df_featuretype = self.variables[(self.variables['type'] == 'Integer') & (self.variables['role'] == 'Feature')]\n",
    "        features = df_featuretype['name'].unique()\n",
    "        self._integer_features = list(features)\n",
    "        # print(self._integer_features)\n",
    "\n",
    "    def get_binary_features(self):\n",
    "        df_featuretype = self.variables[(self.variables['type'] == 'Binary') & (self.variables['role'] == 'Feature')]\n",
    "        features = df_featuretype['name'].unique()\n",
    "        self._binary_features = list(features)\n",
    "        # print(self._binary_features)\n",
    "\n",
    "    def impute_continuous_features(self):\n",
    "        for feature in self._continuous_features:\n",
    "            # calculate mean value for the featue within the featureype\n",
    "            mean_value = self._features[feature].mean()    \n",
    "            # Fill NaN values with the median of the column\n",
    "            self._features.loc[:, feature] = self._features[feature].fillna(mean_value)\n",
    "            # print(\"Mean imputation for {} executed succesfully\".format(feature))\n",
    "\n",
    "    def impute_integer_features(self): \n",
    "        for feature in self._integer_features:\n",
    "            # calculate mean value for the featue within the featureype\n",
    "            mode_value = self._features[feature].mode()[0]    \n",
    "            # Fill NaN values with the median of the column\n",
    "            self._features.loc[:, feature] = self._features[feature].fillna(mode_value)\n",
    "            # print(\"Mode imputation for {} executed succesfully\".format(feature))\n",
    "\n",
    "    def impute_categorical_features(self):\n",
    "        for feature in self._categorical_features:\n",
    "            self._features.loc[:, feature] = self._features[feature].fillna('Not present')\n",
    "            # print(\"Imputation for {} executed succesfully\".format(feature)) \n",
    "\n",
    "    def impute_binary_features(self):\n",
    "        for feature in self._binary_features:\n",
    "            self._features.loc[:, feature] = self._features[feature].fillna('Unkown')\n",
    "            # print(\"Imputation for {} executed succesfully\".format(feature))\n",
    "            \n",
    "    def impute_target(self):\n",
    "        # select target feature\n",
    "        self._target = self._targets['Diagnosis']\n",
    "        self._target = pd.DataFrame(self._target)\n",
    "        \n",
    "        # covert strinf descrriptions to integer featutres\n",
    "        self._target.loc[self._target['Diagnosis']=='appendicitis'] = 1\n",
    "        self._target.loc[self._target['Diagnosis']=='no appendicitis'] = 0\n",
    "\n",
    "        # impute target feature\n",
    "        mode_value = self._target['Diagnosis'].mode()[0]\n",
    "        self._target =  self._target.fillna(mode_value)\n",
    "\n",
    "    def run_eda(self):\n",
    "        print('Running EDA')\n",
    "        print(self._features[self._continuous_features[:5]].describe())\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.pairplot(self._features[self._continuous_features[:5]], height= 2)\n",
    "\n",
    "    def normalize(self):\n",
    "        print('Running normalization')\n",
    "        scaler = MinMaxScaler()\n",
    "        self._continuous_df_features = pd.DataFrame(scaler.fit_transform(self._features[self._continuous_features]), columns = self._features[self._continuous_features].columns)\n",
    "\n",
    "    def encode(self):\n",
    "        self._categorical_df_features = pd.concat([self._features[self._categorical_features],self._features[self._binary_features]], axis = 1)\n",
    "        self._categorical_df_features= pd.get_dummies(self._categorical_df_features, drop_first = True)\n",
    "\n",
    "    def run_pca(self):\n",
    "        pca = PCA(n_components = 3)\n",
    "        pca_result = pca.fit_transform(self._continuous_df_features)\n",
    "        pca_df = pd.DataFrame(pca_result, columns=[f'PC{i+1}' for i in range(pca.n_components_)])\n",
    "\n",
    "        # Explained variance ratio for each component\n",
    "        explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "        # Create the loadings matrix\n",
    "        loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "\n",
    "        # Convert to a DataFrame for better readability\n",
    "        loadings_df = pd.DataFrame(loadings, index=self._continuous_df_features.columns, columns=[f'PC{i+1}' for i in range(loadings.shape[1])])\n",
    "        loadings_df\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.heatmap(loadings_df, annot=True, cmap='coolwarm', fmt=\".2f\", cbar=True, center=0)\n",
    "        plt.title('PCA Loadings Matrix')\n",
    "        plt.xlabel('Principal Components')\n",
    "        plt.ylabel('Features')\n",
    "        plt.show()\n",
    "\n",
    "    def engineer_features(self):\n",
    "        self.selected_features = ['Age','BMI','Height','WBC_Count']\n",
    "        self._continuous_df_features = self._continuous_df_features[self.selected_features]\n",
    "\n",
    "    def integrate_data(self):\n",
    "        # Integración de variables continuas y categóricas\n",
    "        self._X_preprocessed = pd.concat([self._continuous_df_features,self._categorical_df_features], axis = 1)\n",
    "        # Integración de variables integer\n",
    "        self._X_preprocessed = pd.concat([self._X_preprocessed,self._features[self._integer_features]], axis = 1)\n",
    "        # Generación de target preprocesado\n",
    "        self._y_preprocessed = self._target\n",
    "        # Dataframe resultante listo para entrengar el modelo\n",
    "        self._preprocessed_data = pd.concat([self._X_preprocessed,self._target], axis = 1)\n",
    "\n",
    "    def save_preproccesed_data(self):\n",
    "        current_directory = os.getcwd()\n",
    "        parent_directory = os.path.dirname(current_directory)\n",
    "        path = os.path.join(parent_directory,'data/processed/uci_df.csv')\n",
    "        self._preprocessed_data.to_csv(path)\n",
    "        print(\"Data stored at:\", path)\n",
    "\n",
    "    def train_test_split(self):        \n",
    "        self._X_train, self._X_test, self._y_train, self._y_test = train_test_split( self._X_preprocessed\n",
    "                                                        ,self._y_preprocessed.astype(int)\n",
    "                                                        ,train_size = .8\n",
    "                                                        ,test_size=0.2\n",
    "                                                        ,random_state=42\n",
    "                                                        ,stratify= self._y_preprocessed.astype(int)\n",
    "                                                        )\n",
    "        \n",
    "    def train_random_forest(self):\n",
    "\n",
    "        # Initialize the Random Forest Classifier\n",
    "\n",
    "        self._rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        self._rf_classifier.fit(self._X_train, np.array(self.y_train).flatten())\n",
    "        self._y_pred = self._rf_classifier.predict(self.X_test)\n",
    "\n",
    "        self._accuracy = accuracy_score(self._y_test, self._y_pred)\n",
    "        self._confusion_matrix = confusion_matrix(self.y_test, self.y_pred)\n",
    "        # Print accuracy and confusion matrix\n",
    "        print(\"Accuracy of the model:\", round(self._accuracy,4))\n",
    "        print(\"\")\n",
    "\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(self._y_test, self._y_pred))\n",
    "\n",
    "        # Visualize the confusion matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(self._confusion_matrix, annot = True)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.show()\n",
    "\n",
    "    def export_model(self):\n",
    "        current_directory = os.getcwd()\n",
    "        parent_directory = os.path.dirname(current_directory)\n",
    "        path = os.path.join(parent_directory,'models/appendictis_model.pkl')\n",
    "        joblib.dump(self._rf_classifier,path)\n",
    "        print(\"Model stored at:\", path)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Error connecting to server",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/mlops_jovalle/.venv/lib/python3.10/site-packages/ucimlrepo/fetch.py:68\u001b[0m, in \u001b[0;36mfetch_ucirepo\u001b[0;34m(name, id)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_default_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcafile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcertifi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(response)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    562\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 502: Bad Gateway",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[226], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Pipeline\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m AppendicitisModel()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_rawdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39msave_rawdata()\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mget_continuous_features()\n",
      "Cell \u001b[0;32mIn[225], line 141\u001b[0m, in \u001b[0;36mAppendicitisModel.import_rawdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fetch dataset and create dataframes for features, targets, raw_df, and variables.\"\"\"\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Fetch dataset \u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m regensburg_pediatric_appendicitis \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_ucirepo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m938\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Create dataframes (features, targets, variables, raw_df)\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_features \u001b[38;5;241m=\u001b[39m regensburg_pediatric_appendicitis\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfeatures \n",
      "File \u001b[0;32m~/Desktop/mlops_jovalle/.venv/lib/python3.10/site-packages/ucimlrepo/fetch.py:71\u001b[0m, in \u001b[0;36mfetch_ucirepo\u001b[0;34m(name, id)\u001b[0m\n\u001b[1;32m     69\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(response)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError):\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError connecting to server\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# verify that dataset exists \u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[0;31mConnectionError\u001b[0m: Error connecting to server"
     ]
    }
   ],
   "source": [
    "# Pipeline\n",
    "\n",
    "model = AppendicitisModel()\n",
    "\n",
    "model.import_rawdata()\n",
    "model.save_rawdata()\n",
    "\n",
    "model.get_continuous_features()\n",
    "model.get_categorical_features()\n",
    "model.get_integer_features()\n",
    "model.get_binary_features()\n",
    "\n",
    "model.impute_continuous_features()\n",
    "model.impute_integer_features()\n",
    "model.impute_categorical_features()\n",
    "model.impute_binary_features()\n",
    "model.impute_target()\n",
    "\n",
    "# model.run_eda()\n",
    "model.normalize()\n",
    "model.encode()\n",
    "model.run_pca()\n",
    "model.integrate_data()\n",
    "\n",
    "model.save_preproccesed_data()\n",
    "\n",
    "model.train_test_split()\n",
    "model.train_random_forest()\n",
    "model.export_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
